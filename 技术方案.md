---

### **实时数据缓存服务 - 技术设计规约 (TDD)**

**版本**: 1.0
**日期**: 2025-06-27

---

### **1. 项目概述**

#### 1.1. 项目目标
本项目旨在创建一个独立的后台服务，用于实时缓存工业生产数据。服务将从上游的 SQL Server 数据库中拉取数据，并将#### 6.2. 下游接口 (DuckDB 文件)
* **接口形式**: 数据库文件本身 (`realtime_data.duckdb`)
* **数据格式**: 宽表格式，每行包含时间戳和所有标签的值
* **访问协议**: 标准 DuckDB 连接协议
* **支持的客户端**: Python `duckdb` 库、DBeaver、命令行工具等
* **并发模型**: 服务本身对文件进行"一写多读"操作。外部客户端应以**只读模式**连接，以避免文件锁定冲突。DuckDB 的 MVCC 机制能保证外部读取操作不会被内部写入长时间阻塞
* **查询优势**: 宽表格式支持高效的时间范围查询和多标签联合分析个本地的、高性能的嵌入式数据库文件中。该服务需要保证本地缓存中始终只保留最近三天的时序数据，并为下游的数据分析工具（如 Python 脚本）提供一个稳定、高效的直接数据查询接口。

#### 1.2. 核心功能需求
* **数据源**: 从 SQL Server 的`历史表`和`TagDatabase`表获取数据
* **数据存储**: 使用DuckDB嵌入式数据库，采用宽表格式存储时序数据
* **数据窗口**: 维护可配置天数的滚动数据窗口（默认3天）
* **启动行为**: 服务启动时，初始化数据库并加载过去1小时的历史数据，然后拉取TagDatabase当前数据
* **运行时行为**: 以配置的周期（默认10秒）拉取TagDatabase最新数据，动态管理标签变化（加点/少点），清理过期数据
* **宽表存储**: 将时序数据转换为宽表格式，每行包含一个时间戳及所有标签的值，支持动态列管理
* **查询接口**: 本地数据库文件支持多客户端并发只读访问

---

### **2. 系统架构**

系统由三个主要部分构成：数据源、数据处理服务和数据消费端。

* **数据源 (Upstream)**: Microsoft SQL Server 数据库。
* **数据处理服务 (Core Service)**: 本项目需要构建的 Rust 后台服务。它作为数据管道的中心，负责调度、转换和维护本地缓存。
* **数据存储与消费端 (Downstream & Storage)**: 一个本地的 DuckDB 数据库文件 (`.duckdb`)。Python 脚本、数据分析工具或任何支持 DuckDB 的客户端可以直接连接此文件进行数据分析和查询。

**数据流:**
1.  **初始化流程**: `SQL Server` -> `Rust 服务` -> `DuckDB 文件`
2.  **增量更新流程**: `SQL Server` -> `Rust 服务` -> `DuckDB 文件`
3.  **查询流程**: `Python/分析工具` -> `DuckDB 文件`

---

### **3. 技术选型详述**

| 分类 | 技术/库 | 选用理由 | 关键配置/特性 |
| :--- | :--- | :--- | :--- |
| **编程语言** | Rust (最新稳定版) | 提供内存安全、高性能和强大的并发能力，是构建高可靠性后台服务的理想选择。 | - |
| **异步运行时** | `tokio` | Rust 异步生态的事实标准，提供任务调度、定时器、I/O 等核心功能。 | 使用其 `full` 特性集。 |
| **上游数据库驱动** | `tiberius` | 纯 Rust 实现的 TDS 协议库，与 `tokio` 完美集成，用于连接 SQL Server。 | 启用 `chrono` 特性以支持时间类型转换。 |
| **本地缓存数据库** | `duckdb` | **核心选型**。高性能的嵌入式分析型（OLAP）数据库。其列式存储结构对时序数据分析有巨大性能优势。支持并发读写（MVCC），非常适合本项目的“一写多读”场景。 | 启用 `bundled` 和 `chrono` 特性。`bundled` 会将 DuckDB 引擎静态编译到服务程序中，简化部署。 |
| **时间处理** | `chrono` | Rust 标准的时间日期处理库，用于精确处理时间戳和时间窗口计算。 | - |
| **配置管理** | `config` + `serde` | 用于从外部文件（如 `config.toml`）加载配置，实现服务行为的灵活调整。 | `serde` 用于配置结构体的自动序列化/反序列化。 |
| **日志框架** | `tracing` | 提供结构化、上下文感知的日志记录，便于生产环境的监控和问题排查。 | 建议配置为输出 JSON 格式，便于日志聚合系统（如 ELK, Graylog）的采集和分析。 |

---

### **4. 数据模型与数据库 Schema**

#### 4.1. 数据库文件
* **数据库类型**: DuckDB
* **默认文件名**: `realtime_data.duckdb` (应在配置中可指定)

#### 4.2. 表结构 (Schema)
系统采用宽表格式存储时序数据，优化查询性能。

* **表名**: `ts_wide`

| 列名 (Column) | 数据类型 (SQL) | 描述 | 约束/备注 |
| :--- | :--- | :--- | :--- |
| `DateTime` | `TIMESTAMP` | 数据时间戳 (UTC 标准) | `PRIMARY KEY` |
| `tag_*` | `DOUBLE` | 各工业标签的数值，列名动态生成 | 允许 NULL，缺失数据用NULL表示 |

**注**: 标签列名规则
- 特殊字符转换为下划线
- 数字开头的标签名添加 `tag_` 前缀
- 支持动态添加新标签列

#### 4.3. 索引 (Index)
为了优化时间范围查询和数据清理性能。

* **索引名**: `idx_datetime`
* **索引类型**: B-Tree 索引
* **索引列**: `DateTime`
* **目的**: 加速时间范围查询和过期数据删除操作

---

### **5. 核心组件功能规约**

#### 5.1. 配置模块 (`config`)
* **职责**: 提供统一的配置加载和访问接口。
* **实现细节**:
    1.  在项目根目录定义一个 `config.toml` 文件模板。
    2.  定义一个 Rust 结构体，其字段需与 `toml` 文件中的键一一对应，并派生 `serde::Deserialize`。
    3.  **必须包含的配置项**:
        * `database_connection_type`: 数据库连接方式选择 (connection_string/structured_config)
        * `database_url`: 上游 SQL Server 的连接字符串（连接字符串模式）
        * `database`: 结构化数据库配置（结构化模式）
        * `update_interval_secs`: 增量更新周期，单位为秒（例如: 10）
        * `data_window_days`: 数据保留窗口，单位为天（例如: 3）
        * `db_file_path`: 本地 DuckDB 文件的路径
        * `log_level`: 日志级别配置
        * `tables`: 表名配置 (history_table, tag_database_table)
        * `connection`: 连接重试配置 (max_retries, retry_interval_secs等)
        * `batch`: 批量处理配置 (batch_size, max_memory_records等)

#### 5.2. 应用入口与主流程 (`main`)
* **职责**: 初始化服务，协调各个模块的启动和关闭。
* **执行流程**:
    1.  **初始化**:
        * 启动 `tracing` 日志系统。
        * 调用配置模块，加载并验证应用配置。
    2.  **数据库准备**:
        * 根据配置的 `db_file_path`，删除已存在的旧数据库文件并创建新文件
        * 创建并打开一个新的 DuckDB 数据库连接
        * 在该连接上执行 SQL，创建 `ts_wide` 宽表和 `idx_datetime` 索引
        * 关闭此初始化连接
    3.  **任务调度**:
        * 同步执行**初始数据加载模块**，等待其完成后再进行下一步。
        * 将**周期性更新模块**作为一个新的异步任务（`tokio::spawn`）在后台启动。
    4.  **优雅停机**:
        * 监听操作系统的终止信号 (SIGINT, SIGTERM)。
        * 收到信号后，记录停机日志，允许正在执行的任务在短时间内完成，然后退出进程。

#### 5.3. 初始数据加载模块
* **职责**: 在服务启动时，从 SQL Server 加载初始数据以填充本地缓存。
* **执行流程**:
    1.  建立到 SQL Server 的连接
    2.  **查询过去1小时的历史数据**（而非配置的data_window_days天数）
    3.  **查询TagDatabase中的当前数据**
    4.  将查询结果转换为宽表格式，按时间戳分组，每行包含所有标签的值
    5.  **动态检测标签变化并添加新列到宽表**
    6.  使用 DuckDB 的批量插入API进行高性能写入
    7.  **清理超过配置天数的旧数据**
    8.  完成处理后，提交事务并关闭数据库连接

#### 5.4. 周期性更新模块
* **职责**: 定期从 SQL Server 拉取增量数据，管理标签变化，清理本地缓存中的过期数据。
* **执行流程**:
    1.  使用 `tokio::time::interval` 按配置的 `update_interval_secs` 启动定时器
    2.  **在每个定时器周期内，执行以下操作**:
        a. **检测标签变化**:
            i.   查询TagDatabase表中的所有唯一标签名
            ii.  与已知标签集合比较，识别新增和删除的标签
            iii. 对新增标签动态添加列到宽表
            iv.  对删除标签进行标记（保留历史数据但从已知集合移除）
        b. **拉取最新数据**:
            i.   从TagDatabase表获取当前所有标签的最新值
            ii.  使用当前时间作为时间戳（转换为北京时间显示）
        c. **转换并插入宽表**:
            i.   将标签数据转换为宽表格式
            ii.  批量插入到本地DuckDB文件的ts_wide表
        d. **清理过期数据**:
            i.  计算清理截止时间点 `cutoff_ts` (当前时间 - `data_window_days`)
            ii. 在本地 DuckDB 连接上，执行 `DELETE FROM ts_wide WHERE DateTime < ?`
            iii. 记录被删除的行数
        e. **资源释放**: 确保在此周期内打开的所有数据库连接都已关闭

---

### **6. 外部接口规约**

#### 6.1. 上游接口 (SQL Server)
* **依赖表 1**: `历史表` (用于初始加载过去1小时数据)
* **依赖表 2**: `TagDatabase` (用于获取当前数据和检测标签变化)
* **历史表所需列**: `DateTime` (DATETIME), `TagName` (NVARCHAR), `TagVal` (FLOAT/REAL)
* **TagDatabase所需列**: `TagName` (NVARCHAR), `TagVal` (FLOAT/REAL), `DataTime` (可选，增量查询时使用)
* **访问权限**: 服务运行账户必须拥有对上述表的只读 (`SELECT`) 权限

#### 6.2. 下游接口 (DuckDB 文件)
* **接口形式**: 数据库文件本身。
* **访问协议**: 标准 DuckDB 连接协议。
* **支持的客户端**: Python `duckdb` 库、DBeaver、命令行工具等。
* **并发模型**: 服务本身对文件进行“多读一写”操作。外部客户端应以**只读模式**连接，以避免文件锁定冲突并确保最高性能。DuckDB 的 MVCC 机制能保证外部读取操作不会被内部写入长时间阻塞。

---

### **7. 非功能性需求**

#### 7.1. 错误处理与韧性
* 所有 I/O 操作（数据库连接、查询、文件写入）都必须有完善的错误处理逻辑。
* 对于可恢复的错误（如数据库瞬时连接中断），应实施有限次数的**重试机制**（例如，间隔5秒重试3次）。
* 若重试后依然失败，应记录详细的 `ERROR` 级别日志，并继续下一个更新周期，而不是使服务崩溃。

#### 7.2. 日志规范
* **日志级别**:
    * `INFO`: 记录关键生命周期事件（服务启停、任务开始/结束、加载/删除的数据量）。
    * `WARN`: 记录非致命性问题（如重试操作）。
    * `ERROR`: 记录所有导致功能失败的错误。
    * `DEBUG`: 用于开发阶段的详细信息追踪。
* **日志内容**: 每条日志应包含时间戳、日志级别、模块来源以及结构化的消息内容。
* **日志格式**: 建议输出为 **JSON** 格式。

#### 7.3. 部署与运维
* **构建产物**: 一个单独的、无外部依赖的可执行二进制文件（通过 `cargo build --release` 和 DuckDB 的 `bundled` 特性实现）。
* **运行方式**: 推荐将此二进制文件注册为操作系统服务（如 Linux `systemd` 或 Windows Service），以实现开机自启、进程守护和自动重启。
* **资源占用**: 服务应是轻量级的，主要 CPU 消耗集中在更新周期的短暂瞬间，内存占用主要由 DuckDB 自身管理。需监控其 CPU 和内存使用情况。